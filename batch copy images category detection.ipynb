{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook copies images and annotations from the original dataset, to perform cateogry detection\n",
    "\n",
    "you can control how many images per pose (starting from some point) and how many instances to consider as well as which classes\n",
    "\n",
    "we also edit the annotation file because initially all annotations are made by instance not category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "from shutil import copyfile\n",
    "import xml.etree.ElementTree as ET\n",
    "images_per_set = 102\n",
    "start_after = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following code can be used to generate both training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['book','cellphone','hairbrush','mouse','perfume','sunglasses']\n",
    "days = [5,3,5,7,5,3]\n",
    "images_path ='C:/Users/issa/Documents/datasets/ICUB_6/testseenimg/' \n",
    "annotations_path = 'C:/Users/issa/Documents/datasets/ICUB_6/testseenans/'\n",
    "instances_list = [1,2,3,4,5,6,7]\n",
    "for category_name,day_number in zip(classes,days):\n",
    "    in_pose_counter = 0;\n",
    "    j=1;\n",
    "    for inst in instances_list:\n",
    "        dirs = ['D:\\\\2nd_Semester\\\\CV\\\\Project\\\\part1\\\\part1\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\MIX\\\\day'+str(day_number)+'\\\\left\\\\',\n",
    "                'D:\\\\2nd_Semester\\\\CV\\\\Project\\\\part1\\\\part1\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\ROT2D\\\\day'+str(day_number)+'\\\\left\\\\',\n",
    "                'D:\\\\2nd_Semester\\\\CV\\\\Project\\\\part1\\\\part1\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\ROT3D\\\\day'+str(day_number)+'\\\\left\\\\',\n",
    "                'D:\\\\2nd_Semester\\\\CV\\\\Project\\\\part1\\\\part1\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\SCALE\\\\day'+str(day_number)+'\\\\left\\\\',\n",
    "                'D:\\\\2nd_Semester\\\\CV\\\\Project\\\\part1\\\\part1\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\TRANSL\\\\day'+str(day_number)+'\\\\left\\\\']\n",
    "\n",
    "        for dir in dirs:\n",
    "            i=0;\n",
    "            in_pose_counter=0;\n",
    "            if(i>images_per_set):\n",
    "                break;\n",
    "            for innerSubDir,innerDirs,innerFiles in os.walk(dir):\n",
    "                for file in innerFiles:\n",
    "                    \n",
    "                    i = i+1\n",
    "                    if(i>images_per_set):\n",
    "                        break;\n",
    "                    in_pose_counter = in_pose_counter+1\n",
    "                    \n",
    "                    if(in_pose_counter>start_after):\n",
    "                        copyfile(dir+file,images_path+category_name+'_'+str(j)+'.jpg')\n",
    "                        j = j+1\n",
    "    in_pose_counter =0\n",
    "    j =1\n",
    "    for inst in instances_list:\n",
    "        dirs = ['D:\\\\2nd_Semester\\\\CV\\\\Project\\\\Annotations_refined\\Annotations_refined\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\MIX\\\\day'+str(day_number)+'\\\\left\\\\',\n",
    "                'D:\\\\2nd_Semester\\\\CV\\\\Project\\\\Annotations_refined\\Annotations_refined\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\ROT2D\\\\day'+str(day_number)+'\\\\left\\\\',\n",
    "                'D:\\\\2nd_Semester\\\\CV\\\\Project\\\\Annotations_refined\\Annotations_refined\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\ROT3D\\\\day'+str(day_number)+'\\\\left\\\\',\n",
    "                'D:\\\\2nd_Semester\\\\CV\\\\Project\\\\Annotations_refined\\Annotations_refined\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\SCALE\\\\day'+str(day_number)+'\\\\left\\\\',\n",
    "                'D:\\\\2nd_Semester\\\\CV\\\\Project\\\\Annotations_refined\\Annotations_refined\\\\'+category_name+'\\\\'+category_name+str(inst)+'\\\\TRANSL\\\\day'+str(day_number)+'\\\\left\\\\']\n",
    "\n",
    "        for dir in dirs:\n",
    "            i=0;\n",
    "            in_pose_counter=0\n",
    "            if(i>images_per_set):\n",
    "                break;\n",
    "            for innerSubDir,innerDirs,innerFiles in os.walk(dir):\n",
    "                for file in innerFiles:\n",
    "                    i = i+1\n",
    "                    if(i>images_per_set):\n",
    "                        break;\n",
    "                    in_pose_counter = in_pose_counter+1\n",
    "                                \n",
    "                    if(in_pose_counter>start_after):\n",
    "                        root = ET.parse(dir+file)\n",
    "                        for node in root.findall(\".//object/name\"):\n",
    "                            node.text=category_name\n",
    "                        outputPath = annotations_path+category_name+'_'+str(j)+'.xml'\n",
    "                    \n",
    "                        j = j+1\n",
    "                        root.write(outputPath)\n",
    "                                     \n",
    "                    \n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part produces the train/val sets, we set the classes and the list containing the number of images per class, then we split the list and generate the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = np.arange(1,2001)\n",
    "classes = ['book','cellphone','hairbrush','mouse','perfume','sunglasses']\n",
    "for category in classes:\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(x, x, test_size=0.25)\n",
    "\n",
    "    file = open(\"datasets//ICUB_6//train.txt\",\"a\") \n",
    "\n",
    "    for i in xtrain:\n",
    "        file.write(category+'_'+str(i)+'\\n')\n",
    "\n",
    "    file.close()\n",
    "    file = open(\"datasets//ICUB_6//val.txt\",\"a\") \n",
    "\n",
    "    for i in xtest:\n",
    "        file.write(category+'_'+str(i)+'\\n')\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this part generates the test set list, no splitting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "classes = ['book','cellphone','hairbrush','mouse','perfume','sunglasses']\n",
    "x = np.arange(1,71)\n",
    "file = open(\"datasets//ICUB_6//testseen.txt\",\"a\") \n",
    "for category in classes:\n",
    "    for i in x:\n",
    "        file.write(category+'_'+str(i)+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
